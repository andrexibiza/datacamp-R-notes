---
title: "Working with Dates and Times in R"
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

# Chapter 1: Dates and Times in R

## Video 1.1: Introduction to dates

### Dates

Different conventions in different places

27th Feb 2013 \* NZ: 27/2/2013 \* USA: 2/27/2013

### ISO 8601 YYYY-MM-DD

-   Values ordered from the largest to smallest unit of time.
-   Each has a fixed number of digits, must be padded with leading
    zeros.
-   Either, no separators for computers, or `-` in dates.
-   1st of January 2011 -\> 2011-01-01

### Dates in R

-   Packages that import dates: `readr`, `anytime`.

```{r}
2003-02-27
# interpreted as mathematical function
```

```{r}
"2003-02-27"
# interpreted as character string
```

```{r}
str("2003-02-27")
# interpreted as character string
```

```{r}
as.Date("2003-02-27")
```

```{r}
str(as.Date("2003-02-27"))
```

## Specifying dates

As you saw in the video, R doesn't know something is a date unless you
tell it. If you have a character string that represents a date in the
ISO 8601 standard you can turn it into a Date using the as.Date()
function. Just pass the character string (or a vector of character
strings) as the first argument.

In this exercise you'll convert a character string representation of a
date to a Date object.

```{r}
# The date R 3.0.0 was released
x <- "2013-04-03"

# Examine structure of x
str(x)
```

```{r}
# Use as.Date() to interpret x as a date
x_date <- as.Date(x)

# Examine structure of x_date
str(x_date)

# Store April 10 2014 as a Date
april_10_2014 <- as.Date("2014-04-10")
```

## Automatic import

Sometimes you'll need to input a couple of dates by hand using
`as.Date()` but it's much more common to have a column of dates in a
data file.

Some functions that read in data will automatically recognize and parse
dates in a variety of formats. In particular the import functions, like
`read_csv()`, in the `readr` package will recognize dates in a few
common formats.

There is also the `anytime()` function in the `anytime` package whose
sole goal is to automatically parse strings as dates regardless of the
format.

```{r}
# Load the readr package
library(readr)

# Use read_csv() to import rversions.csv
releases <- read_csv("rversions.csv")

# Examine the structure of the date column
str(releases$date)
```

```{r}
# Load the anytime package
library(anytime)

# Various ways of writing Sep 10 2009
sep_10_2009 <- c("September 10 2009", "2009-09-10", "10 Sep 2009", "09-10-2009")

# Use anytime() to parse sep_10_2009
anytime(sep_10_2009)
```

## Video 1.2: Why use dates?

### Dates act like numbers

`Date` objects are stored as days since `1970-01-01`.

```{r}
as.Date("2003-02-27") > as.Date("2002-02-27")
```

```{r}
as.Date("2003-02-27") + 1
```

```{r}
as.Date("2003-02-27") - as.Date("2002-02-27")
```

### Plotting with dates

```{r}
x <- c(as.Date("2003-02-27"),
       as.Date("2003-03-27"),
       as.Date("2003-04-27"))
plot(x, 1:3)
```

```{r}
library(ggplot2)
ggplot() +
  geom_point(aes(x = x, y = 1:3))
```

### R releases

```{r}
# previously imported from csv
releases
```

## Plotting

If you plot a Date on the axis of a plot, you expect the dates to be in
calendar order, and that's exactly what happens with `plot()` or
`ggplot()`.

In this exercise you'll make some plots with the R version releases data
from the previous exercises using `ggplot2`. There are two big
differences when a Date is on an axis:

1)  If you specify limits they must be `Date` objects.
2)  To control the behavior of the scale you use the `scale_x_date()`
    function.

**Instructions** - Make a plot of releases over time by setting the x
argument of the aes() function to the date column. - Zoom in to the
period from 2010 to 2014 by specifying limits from "2010-01-01" to
"2014-01-01". Notice these strings need to be wrapped in as.Date() to be
interpreted as Date objects. - Adjust the axis labeling by specifying
date_breaks of "10 years" and date_labels of "%Y".

```{r}
# library(ggplot2)

# Set the x axis to the date column
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major)))
```

```{r}
# Limit the axis to between 2010-01-01 and 2014-01-01
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  xlim(as.Date("2010-01-01"), as.Date("2014-01-01"))
```

```{r}
# Specify breaks every ten years and labels with "%Y"
ggplot(releases, aes(x = date, y = type)) +
  geom_line(aes(group = 1, color = factor(major))) +
  scale_x_date(date_breaks = "10 years", date_labels = "%Y")
```

## Arithmetic and logical operators

Since `Date` objects are internally represented as the number of days
since `1970-01-01` you can do basic math and comparisons with dates. You
can compare dates with the usual logical operators (`<`, `==`, `>`
etc.), find extremes with `min()` and `max()`, and even subtract two
dates to find out the time between them.

In this exercise you'll see how these operations work by exploring the
last R release. You'll see `Sys.date()` in the code, it simply returns
today's date.

**Instructions** - Find the date of the most recent release by calling
`max()` on the date column in `releases`. - Find the rows in releases
that have the most recent date, by specifying the comparison
`date == last_release_date` in `filter()`. - Print `last_release` to see
which release this was. - Calculate how long it has been since the most
recent release by subtracting `last_release_date` from `Sys.Date()`.

```{r}
# # Find the largest date
# last_release_date <- max(releases$date)
# 
# # Filter row for last release
# last_release <- filter(releases, date == last_release_date)
# 
# # Print last_release
# last_release
# 
# # A tibble: 1 x 7
#   major minor patch date       datetime            time     type 
#   <int> <int> <int> <date>     <dttm>              <time>   <chr>
# 1     3     4     1 2017-06-30 2017-06-30 07:04:11 07:04:11 patch

# # How long since last release?
# Sys.Date() - last_release_date
# 
# Time difference of 2792 days
```

## Video 1.3: What about times?

### ISO 8601

**HH:MM:SS** - Largest unit to smallest - Fixed digits - Hours: 00 --
24 - Minutes: 00 -- 59 - Seconds: 00 -- 60 (60 only for leap seconds) -
No separator or `:`

### Datetimes in R

-   Two objects types:
    -   `POSIXlt`: list with named components
    -   `POSIXct`: number of seconds since `1970-01-01 00:00:00`
-   `POSIXct` will go in a data frame
-   `as.POSIX.ct()` turns a string into a `POSIXct` object
    -   any datetimes not in ISO 8601 need to be parsed specially.

```{r}
x <- as.POSIXct("1970-01-01 00:10:00")
str(x)
```

### Timezones

-   `"2013-02-27T18:00:00"` - 6pm local time
-   `"2013-02-27T18:00:00Z"` - 6pm UTC
-   `"2013-02-27T18:00:00-0800"` - 6pm in Oregon (PST)

```{r}
as.POSIXct("2013-02-27T18:00:00Z")
```

-   `UTC` is a coordinated international standard that does not observe
    Daylight Savings.

```{r}
as.POSIXct("2013-02-27T18:00:00Z", tz = "UTC")
```

### Datetimes behave nicely too

Once a `POSIXct` object, datetimes can be: - Compared - Subtracted -
Plotted

## Getting datetimes into R

Just like dates without times, if you want R to recognize a string as a
datetime you need to convert it, although now you use `as.POSIXct()`.
`as.POSIXct()` expects strings to be in the format
`YYYY-MM-DD HH:MM:SS`.

The only tricky thing is that times will be interpreted in local time
based on your machine's set up. You can check your timezone with
`Sys.timezone()`. If you want the time to be interpreted in a different
timezone, you just set the `tz` argument of `as.POSIXct()`. You'll learn
more about time zones in Chapter 4.

In this exercise you'll input a couple of datetimes by hand and then see
that `read_csv()` also handles datetimes automatically in a lot of
cases.

**Instructions** - Use `as.POSIXct()` and an appropriate string to input
the datetime corresponding to Oct 1st 2010 at 12:12:00. - Enter the same
datetime again, but now specify the timezone as
`"America/Los_Angeles"`. - Use `read_csv()` to read in `rversions.csv`
again. - Examine the structure of the datetime column to verify
`read_csv()` has correctly interpreted it as a datetime.

```{r}
# Use as.POSIXct to enter the datetime 
as.POSIXct("2010-10-01 12:12:00")

# Use as.POSIXct again but set the timezone to `"America/Los_Angeles"`
as.POSIXct("2010-10-01 12:12:00", tz = "America/Los_Angeles")

# Use read_csv to import rversions.csv
releases <- read_csv("rversions.csv")

# Examine structure of datetime column
str(releases$datetime)
```

## Datetimes behave nicely too

Just like `Date` objects, you can plot and do math with `POSIXct`
objects.

As an example, in this exercise you'll see how quickly people download
new versions of R, by examining the download logs from the RStudio CRAN
mirror.

R 3.2.0 was released at "2015-04-16 07:13:33" so
`cran-logs_2015-04-17.csv` contains a random sample of downloads on the
16th, 17th and 18th.

**Instructions**

-   Use `read_csv()` to import `cran-logs_2015-04-17.csv`.
-   Print `logs` to see the information we have on each download.
-   Store the R 3.2.0 release time as a `POSIXct` object.
-   Find out when the first request for 3.2.0 was made by filtering for
    values in the `datetime` column that are greater than
    `release_time`. Finally see how downloads increase by creating
    histograms of download time for 3.2.0 and the previous version
    3.1.3. We've provided most of the code, you just need to specify the
    `x` aesthetic to be the `datetime` column.

```{r}
# Import "cran-logs_2015-04-17.csv" with read_csv()
logs <- read_csv("cran-logs_2015-04-17.csv")

# Print logs
print(logs)
```

```{r}
library(dplyr)
# Store the release time as a POSIXct object
release_time <- as.POSIXct("2015-04-16 07:13:33", tz = "UTC")

# When is the first download of 3.2.0?
logs %>% 
  filter(datetime > release_time,
    r_version == "3.2.0")

# Examine histograms of downloads by version
ggplot(logs, aes(x = datetime)) +
  geom_histogram() +
  geom_vline(aes(xintercept = as.numeric(release_time)))+
  facet_wrap(~ r_version, ncol = 1)
```

## Video 1.4: Why `lubridate`?

### `lubridate`

-   Make working with dates and times in R easy!
-   `tidyverse` pacage
    -   Plays nicely with builtin datetime objects
    -   Designed for humans not computers
-   Plays nicely with other tidyverse packages
-   Consistent behavior regardless of underlying object

### Parsing a wide range of formats

-   `lubridate` makes it easy to parse a character string into a
    datetime object.
-   Although R has built-in parsing functions:
    -   `lubridate`'s functions are simpler to use,
    -   more forgiving of different formats,
    -   and even allow parsing of many formats in one vector.

```{r}
library(lubridate)
ymd("2013-02-27")
```

```{r}
dmy("27/2/13")
```

```{r}
parse_date_time(c("Feb 27th, 2017", "27th Feb 2017"),
                order = c("mdy", "dmy"))
```

### Manipulating datetimes

```{r}
# Extract components
akl_daily <- read_csv("akl_weather_daily.csv")
akl_daily <- akl_daily %>% 
  mutate(
    year = year(date),
    yday = yday(date),
    month = month(date, label = TRUE)
  )
```

### Time spans

-   `lubridate` also has special objects for handling time spans - the
    time that passes between two data points.
    -   learn how to use time spans to generate sequences of datetimes
        and calculate the length of time intervals like the reign of the
        kings and queens of England.

### Other `lubridate` features

-   Handling timezones
-   Fast parsing of standard formats
-   Outputting datetimes

------------------------------------------------------------------------

# Chapter 2: Parsing and Manipulating Dates and Times with `lubridate`

## Video 2.1: Parsing dates with `lubridate`

### `ymd()`

-   27th of February 2013
-   `ymd()` - year, then month, then day
    -   does a good job handling dates that are in the right order, but
        may not be exactly ISO 8601
        -   ignores separators
        -   units don't have to be numeric

```{r}
ymd("2013-02-27")
```

```{r}
ymd("2013.02.27")
```

```{r}
ymd("2013 Feb 27th")
```

### Friends of `ymd()`

-   The function name specifies the expected format of the date.

-   If you don't specify a timezone, `lubridate` will assume `UTC`.

`ymd()`, `ydm()`, `mdy()`, `myd()`, `dmy()`, `dym()`

```{r}
dmy("27-02-2013")
```

```{r}
mdy("02-27-2013")
```

```{r}
dmy_hm("27-02-2013 12:12pm")
```

### `parse_date_time(x = ___, order = ___)`

-   Also parses dates, but you specify the order in a separate argument.

```{r}
parse_date_time("27-02-2013", order = "dmy")
```

```{r}
parse_date_time(c("27-02-2013", "2013 Feb 27th"), order = c("dmy", "ymd"))
```

### Formatting characters

-   All of these on help page for `parse_date_time`

| Character | Meaning                  |
|-----------|--------------------------|
| `d`       | numeric day of the month |
| `m`       | month of the year        |
| `y`       | year with century        |
| `Y`       | year without century     |
| `H`       | hours (00-23)            |
| `M`       | minutes (00-59)          |
| `S`       | seconds (00-59)          |
| `a`       | abbreviated weekday      |
| `A`       | full weekday             |
| `b`       | abbreviated month name   |
| `B`       | full month name          |
| `I`       | hours (01-12)/12-hr      |
| `p`       | AM/PM                    |
| `z`       | timezone offset from UTC |

## Selecting the right parsing function

`lubridate` provides a set of functions for parsing dates of a known
order. For example, `ymd()` will parse dates with year first, followed
by month and then day. The parsing is flexible, for example, it will
parse the `m` whether it is numeric (e.g. `9` or `09`), a full month
name (e.g. `September`), or an abbreviated month name (e.g. `Sep`).

All the functions with `y`, `m` and `d` in any order exist. If your
dates have times as well, you can use the functions that start with
`ymd`, `dmy`, `mdy` or `ydm` and are followed by any of `_h`, `_hm` or
`_hms`.

To see all the functions available look at `ymd()` for dates and
`ymd_hms()` for datetimes.

Here are some challenges. In each case we've provided a date, your job
is to choose the correct function to parse it.

**Instructions**

For each date the ISO 8601 format is displayed as a comment after it, to
help you check your work

-   Choose the correct function to parse `x`.

-   Choose the correct function to parse `y`.

-   Choose the correct function to parse `z`.

```{r}
library(lubridate)

# Parse x 
x <- "2010 September 20th" # 2010-09-20
ymd(x)

# Parse y 
y <- "02.01.2010"  # 2010-01-02
dmy(y)

# Parse z 
z <- "Sep, 12th 2010 14:00"  # 2010-09-12T14:00
mdy_hm(z)
```

## Specifying an order with `parse_date_time()`

What about if you have something in a really weird order like `dym_msh`?
There's no named function just for that order, but that is where
`parse_date_time()` comes in. `parse_date_time()` takes an additional
argument, `orders`, where you can specify the order of the components in
the date.

For example, to parse `"2010 September 20th"` you could say
`parse_date_time("2010 September 20th", orders = "ymd")` and that would
be equivalent to using the `ymd()` function from the previous exercise.

One advantage of `parse_date_time()` is that you can use more format
characters. For example, you can specify weekday names with `A`, `I` for
12 hour time, am/pm indicators with `p` and many others. You can see a
whole list on the help page `?parse_date_time`.

Another big advantage is that you can specify a vector of orders, and
that allows parsing of dates where multiple formats might be used.

You'll try it out in this exercise.

**Instructions**

-   `x` is a trickier datetime. Use the clues in the instructions to
    parse `x`.

-   `two_orders` has two different orders, parse both by specifying the
    order to be `c("mdy", "dmy")`.

-   Parse `short_dates` with `orders = c("dOmY", "OmY", "Y")`. *What
    happens to the dates that don't have months or days specified?*

```{r}
# Specify an order string to parse x
x <- "Monday June 1st 2010 at 4pm"
parse_date_time(x, orders = "AmdyIp")

# Specify order to include both "mdy" and "dmy"
two_orders <- c("October 7, 2001", "October 13, 2002", "April 13, 2003", 
  "17 April 2005", "23 April 2017")
parse_date_time(two_orders, orders = c("mdy", "dmy"))

# Specify order to include "dOmY", "OmY" and "Y"
short_dates <- c("11 December 1282", "May 1372", "1253")
parse_date_time(short_dates, orders = c("dOmY", "OmY", "Y"))
```

## Video 2.2: Weather in Auckland

### `make_date(year, month, day)`

```{r}
make_date(year = 2013, month = 2, day = 27)
```

`make_datetime(year, month, day, hour, minute, second)` for datetimes

### `dplyr` review

-   `mutate()` - add new columns
-   `filter()` - subset rows
-   `select()` - subset columns
-   `arrange()` - reorder rows
-   `summarize()` - summarize data
-   `group_by()` - group data, useful in conjunction with `summarize()`

### Pipe `%>%`

```{r}
# Without the pipe: nested functions
summarise(group_by(filter(releases, major == 3), minor), n =  n())

# With pipe: more linear
releases %>%   
  filter(major == 3) %>%   
  group_by(minor) %>%   
  summarise(n = n())

```

## **Import daily weather data**

In practice you won't be parsing isolated dates and times, they'll be
part of a larger dataset. Throughout the chapter after you've mastered a
skill with a simpler example (the release times of R for example),
you'll practice your `lubridate` skills in context by working with
weather data from Auckland NZ.

There are two data sets: `akl_weather_daily.csv` a set of once daily
summaries for 10 years, and `akl_weather_hourly_2016.csv` observations
every half hour for 2016. You'll import the daily data in this exercise
and the hourly weather in the next exercise.

You'll be using functions from `dplyr`, so if you are feeling rusty, you
might want to review `filter()`, `select()` and `mutate()`.

**Instructions**

-   Import the daily data, `"akl_weather_daily.csv"` with `read_csv()`.

-   Print `akl_daily_raw` to confirm the `date` column hasn't been
    interpreted as a date. *Can you see why?*

-   Using `mutate()` overwrite the column `date` with a parsed version
    of `date`. You need to specify the parsing function. Hint: the first
    date should be September 1.

-   Print `akl_daily` to verify the `date` column is now a `Date`.

-   Take a look at the data by plotting `date` on the x-axis and
    `max_temp` of the y-axis.

```{r}
library(lubridate)
library(readr)
library(dplyr)
library(ggplot2)

# Import CSV with read_csv()
akl_daily_raw <- read_csv("akl_weather_daily.csv")

# Print akl_daily_raw
print(akl_daily_raw)

# Parse date 
akl_daily <- akl_daily_raw %>%
  mutate(date = ymd(date))

# Print akl_daily
print(akl_daily)

# Plot to check work
ggplot(akl_daily, aes(x = date, y = max_temp)) +
  geom_line() 
```

## **Import hourly weather data**

The hourly data is a little different. The date information is spread
over three columns `year`, `month` and `mday`, so you'll need to use
`make_date()` to combine them.

Then the time information is in a separate column again, `time`. It's
quite common to find date and time split across different variables. One
way to construct the datetimes is to paste the `date` and `time`
together and then parse them. You'll do that in this exercise.

**Instructions**

-   Import the hourly data, `"akl_weather_hourly_2016.csv"` with
    `read_csv()`, then print `akl_hourly_raw` to confirm the date is
    spread over `year`, `month` and `mday`.

-   Using `mutate()` create the column `date` with using `make_date()`.

-   We've pasted together the `date` and `time` columns. Create
    `datetime` by parsing the `datetime_string` column.

-   Take a look at the `date`, `time` and `datetime` columns to verify
    they match up.

-   Take a look at the data by plotting `datetime` on the x-axis and
    `temperature` of the y-axis.

```{r}
library(lubridate)
library(readr)
library(dplyr)
library(ggplot2)

# Import "akl_weather_hourly_2016.csv"
akl_hourly_raw <- read_csv("akl_weather_hourly_2016.csv")

# Print akl_hourly_raw
print(akl_hourly_raw)

# Use make_date() to combine year, month and mday 
akl_hourly  <- akl_hourly_raw  %>% 
  mutate(date = make_date(year = year, month = month, day = mday))

# Parse datetime_string 
akl_hourly <- akl_hourly  %>% 
  mutate(
    datetime_string = paste(date, time, sep = "T"),
    datetime = ymd_hms(datetime_string)
  )

# Print date, time and datetime columns of akl_hourly
akl_hourly %>% select(date, time, datetime)

# Plot to check work
ggplot(akl_hourly, aes(x = datetime, y = temperature)) +
  geom_line()
```

## Video 2.3: Extracting parts of a datetime

Once you've got dates in R, you'll often find yourself pulling them
apart again. Why? Because exploring patterns in time often involves
summarizing at different levels of resolution, like grouping data into
months or averaging over hours.

### Extracting components

-   `year()`
-   `month()`
-   `day()`

```{r}
x <- ymd("2013-02-23")
year(x)
```

```{r}
month(x)
```

```{r}
day(x)
```

### Extracting parts of a `datetime`

| Function   | Extracts                 |
|------------|--------------------------|
| `year()`   | year with century        |
| `month()`  | month of the year (1-12) |
| `day()`    | day of the month (1-31)  |
| `hour()`   | hour (0-23)              |
| `min()`    | minute (0-59)            |
| `second()` | second (0-59)            |
| `wday()`   | day of the week (1-7)    |
| `tz()`     | timezone                 |
| `yday()`   | day of the year (1-365)  |

### Setting parts of a `datetime`

```{r}
x
```

```{r}
year(x) <- 2017
x
```

### Other useful functions

| Function      | Extracts                         |
|---------------|----------------------------------|
| `leap_year()` | logical if year is a leap year   |
| `am()`        | logical if time is AM            |
| `pm()`        | logical if time is PM            |
| `dst()`       | logical if daylight savings time |
| `quarter()`   | quarter of the year (1-4)        |
| `semester()`  | semester of the year (1-2)       |

## **What can you extract?**

As you saw in the video, components of a datetime can be extracted by
`lubridate` functions with the same name like `year()`, `month()`,
`day()`, `hour()`, `minute()` and `second()`. They all work the same way
just pass in a datetime or vector of datetimes.

There are also a few useful functions that return other aspects of a
datetime like if it occurs in the morning `am()`, during daylight
savings `dst()`, in a `leap_year()`, or which `quarter()` or
`semester()` it occurs in.

Try them out by exploring the release times of R versions using the data
from Chapter 1.

**Instructions**

We've put `release_time`, the `datetime` column of the `releases`
dataset from Chapter 1, in your workspace.

-   Examine the `head()` of `release_time` to verify this is a vector of
    datetimes.

-   Extract the month from `release_time` and examine the first few with
    `head()`.

-   To see which months have most releases, extract the month then pipe
    to `table()`.

-   Repeat, to see which years have the most releases.

-   Do releases happen in the morning (UTC)? Find out if the hour of a
    release is less than `12` and summarise with `mean()`.

-   Alternatively use `am()` to find out how often releases happen in
    the morning.

```{r}
release_time <- releases$datetime

# Examine the head() of release_time
head(release_time)

# Examine the head() of the months of release_time
head(month(release_time))

# Extract the month of releases 
month(release_time) %>% table()

# Extract the year of releases
year(release_time) %>% table()

# How often is the hour before 12 (noon)?
mean(hour(release_time) < 12)

# How often is the release in am?
mean(am(release_time))
```

## **Adding useful labels**

In the previous exercise you found the month of releases:

```         
head(month(release_time)) 
```

and received numeric months in return. Sometimes it's nicer (especially
for plotting or tables) to have named months. Both the `month()` and
`wday()` (day of the week) functions have additional arguments `label`
and `abbr` to achieve just that. Set `label = TRUE` to have the output
labelled with month (or weekday) names, and `abbr = FALSE` for those
names to be written in full rather than **abbr**eviated.

For example, try running:

```         
head(month(release_time, label = TRUE, abbr = FALSE)) 
```

Practice by examining the popular days of the week for R releases.

**Instructions**

`releases` is now a data frame with a column called `datetime` with the
release time.

-   First, see what `wday()` does without labeling, by calling it on the
    `datetime` column of `releases` and tabulating the result. *Do you
    know if `1` is Sunday or Monday?*

-   Repeat above, but now use labels by specifying the `label` argument.
    *Better, right?*

-   Now store the labelled weekdays in a new column called `wday`.

-   Create a barchart of releases by weekday, facetted by the type of
    release.

```{r}
# library(ggplot2)

# Use wday() to tabulate release by day of the week
wday(releases$datetime) %>% table()

# Add label = TRUE to make table more readable
wday(releases$datetime, label = TRUE) %>% table()

# Create column wday to hold labelled week days
releases$wday <- wday(releases$datetime, label = TRUE)

# Plot barchart of weekday by type of release
ggplot(releases, aes(wday)) +
  geom_bar() +
  facet_wrap(~ type, ncol = 1, scale = "free_y")
```

## **Extracting for plotting**

Extracting components from a datetime is particularly useful when
exploring data. Earlier in the chapter you imported daily data for
weather in Auckland, and created a time series plot of ten years of
daily maximum temperature. While that plot gives you a good overview of
the whole ten years, it's hard to see the annual pattern.

In this exercise you'll use components of the dates to help explore the
pattern of maximum temperature over the year. The first step is to
create some new columns to hold the extracted pieces, then you'll use
them in a couple of plots.

## **Instructions**

**100 XP**

-   Use `mutate()` to create three new columns: `year`, `yday` and
    `month` that respectively hold the same components of the `date`
    column. Don't forget to label the months with their names.

-   Create a plot of `yday` on the x-axis, `max_temp` of the y-axis
    where lines are grouped by `year`. *Each year is a line on this
    plot, with the x-axis running from Jan 1 to Dec 31.*

-   To take an alternate look, create a [**ridgeline
    plot**](https://blog.revolutionanalytics.com/2017/07/joyplots.html)(formerly
    known as a joyplot) with `max_temp` on the x-axis, `month` on the
    y-axis, using `geom_density_ridges()` from the `ggridges` package.

```{r}
library(ggplot2)
library(dplyr)
library(ggridges)

# Add columns for year, yday and month
akl_daily <- akl_daily %>%
  mutate(
    year = year(date),
    yday = yday(date),
    month = month(date, label = TRUE))

# Plot max_temp by yday for all years
ggplot(akl_daily, aes(x = yday, y = max_temp)) +
  geom_line(aes(group = year), alpha = 0.5)

# Examine distribution of max_temp by month
ggplot(akl_daily, aes(x = max_temp, y = month, height = ..density..)) +
  geom_density_ridges(stat = "density")
```

## **Extracting for filtering and summarizing**

Another reason to extract components is to help with filtering
observations or creating summaries. For example, if you are only
interested in observations made on weekdays (i.e. not on weekends) you
could extract the weekdays then filter out weekends, e.g.
`wday(date) %in% 2:6`.

In the last exercise you saw that January, February and March were great
times to visit Auckland for warm temperatures, but will you need a
raincoat?

In this exercise you'll find out! You'll use the hourly data to
calculate how many days in each month there was any rain during the day.

**Instructions**

-   Create new columns for the hour and month of the observation from
    `datetime`. Make sure you label the month.

-   Filter to just daytime observations, where the hour is greater than
    or equal to `8` and less than or equal to `22`.

-   Group the observations first by `month`, then by `date`, and
    summarise by using `any()` on the `rainy` column. *This results in
    one value per day*

-   Summarise again by summing `any_rain`. *This results in one value
    per month*

```{r}
# Create new columns hour, month and rainy
akl_hourly <- akl_hourly %>%
  mutate(
    hour = hour(datetime),
    month = month(datetime, label = TRUE),
    rainy = weather == "Precipitation"
  )

# Filter for hours between 8am and 10pm (inclusive)
akl_day <- akl_hourly %>% 
  filter(hour >= 8, hour <= 22)

# Summarise for each date if there is any rain
rainy_days <- akl_day %>% 
  group_by(month, date) %>%
  summarise(
    any_rain = any(rainy)
  )

# Summarise for each month, the number of days with rain
rainy_days %>% 
  summarise(
    days_rainy = sum(any_rain)
  )
```

## Video 2.4: Rounding datetimes

### Rounding versus extracting

-   Rounding a date will always result in another date object of the
    same type.

```{r}
release_time <- releases$datetime
head(release_time)
```

```{r}
head(release_time) %>% 
       hour()
```

```{r}
head(release_time) %>% 
  floor_date(unit = "hour")
```

### Rounding in `lubridate`

-   `round_date()` = round to **nearest**
-   `ceiling_date()` = round **up**
-   `floor_date()` = round **down**
-   Possible values of `unit`:
    -   `"second"`
    -   `"minute"`
    -   `"hour"`
    -   `"day"`
    -   `"week"`
    -   `"month"`
    -   `"bimonth"`
    -   `"quarter"`
    -   `"halfyear"`
    -   `"year"`
    -   or multiples, e.g. `"2 years"`, `"5 minutes"`

## **Practice rounding**

As you saw in the video, `round_date()` rounds a date to the nearest
value, `floor_date()` rounds down, and `ceiling_date()` rounds up.

All three take a `unit` argument which specifies the resolution of
rounding. You can specify `"second"`, `"minute"`, `"hour"`, `"day"`,
`"week"`, `"month"`, `"bimonth"`, `"quarter"`, `"halfyear"`, or
`"year"`. Or, you can specify any multiple of those units, e.g.
`"5 years"`, `"3 minutes"` etc.

Try them out with the release datetime of R 3.4.1.

**Instructions**

-   Choose the right function and units to round `r_3_4_1` down to the
    nearest day.

-   Choose the right function and units to round `r_3_4_1` to the
    nearest 5 minutes.

-   Choose the right function and units to round `r_3_4_1` up to the
    nearest week.

-   Find the time elapsed on the day of release at the time of release
    by subtracting `r_3_4_1` rounded down to the day from `r_3_4_1`.

```{r}
r_3_4_1 <- ymd_hms("2016-05-03 07:13:28 UTC")

# Round down to day
floor_date(r_3_4_1, unit = "day")

# Round to nearest 5 minutes
round_date(r_3_4_1, unit = "5 minutes")

# Round up to week 
ceiling_date(r_3_4_1, unit = "week")

# Subtract r_3_4_1 rounded down to day
r_3_4_1 - floor_date(r_3_4_1, unit = "day")
```

## **Rounding with the weather data**

When is rounding useful? In a lot of the same situations extracting date
components is useful. The advantage of rounding over extracting is that
it maintains the context of the unit. For example, extracting the hour
gives you the hour the datetime occurred, but you lose the day that hour
occurred on (unless you extract that too), on the other hand, rounding
to the nearest hour maintains the day, month and year.

As an example you'll explore how many observations per hour there really
are in the hourly Auckland weather data.

**Instructions**

-   Create a new column called `day_hour` that is `datetime` rounded
    down to the nearest hour.

-   Use `count()` on `day_hour` to count how many observations there are
    in each hour. *What looks like the most common value?*

-   Extend the pipeline, so that after counting, you filter for
    observations where `n` is not equal to `2`.

```{r}
# Create day_hour, datetime rounded down to hour
akl_hourly <- akl_hourly %>%
  mutate(
    day_hour = floor_date(datetime, unit = "hour")
  )

# Count observations per hour  
akl_hourly %>% 
  count(day_hour) 

# Find day_hours with n != 2  
akl_hourly %>% 
  count(day_hour) %>%
  filter(n != 2) %>% 
  arrange(desc(n))
```

# Chapter 3: Arithmetic with Days and Times

## Video 3.1: Taking differences of datetimes

### Arithmetic for datetimes

-   `datetime_1 - datetime2`: subtraction for time elapsed

-   `datetime_1 + (2 * timespan)`: addition and multiplication for
    generating new datetimes in the past or future.

-   `timespan1`/`timespan2`: division for change of units

### Subtraction of datetimes

```{r}
releases <- read_csv("rversions.csv")
last_release <- filter(releases, date == max(date))
```

```{r}
Sys.Date() - last_release$date
```

```{r}
difftime(Sys.Date(), last_release$date)
```

-   `time1 - time2` is the same as `difftime(time1, time2)`

### `difftime()`

`units =` `"secs"`, `"mins"`, `"hours"`, `"days"`, or `"weeks"`

```{r}
difftime(Sys.Date(), last_release$date, units = "secs")
```

```{r}
difftime(Sys.Date(), last_release$date, units = "weeks")

```

### `now()` and `today()`

```{r}
today()
```

```{r}
str(today())
```

```{r}
now()
```

```{r}
str(now())
```

## **How long has it been?**

To get finer control over a difference between datetimes use the `base`
function `difftime()`. For example instead of `time1 - time2`, you use
`difftime(time1, time2)`.

`difftime()` takes an argument `units` which specifies the units for the
difference. Your options are `"secs"`, `"mins"`, `"hours"`, `"days"`, or
`"weeks"`.

To practice you'll find the time since the first man stepped on the
moon. You'll also see the `lubridate` functions `today()` and `now()`
which when called with no arguments return the current date and time in
your system's timezone.

**Instructions**

-   Apollo 11 landed on July 20, 1969. Use `difftime()` to find the
    number of days between `today()` and `date_landing`.

-   Neil Armstrong stepped onto the surface at 02:56:15 UTC. Use
    `difftime()` to find the number of seconds between `now()` and
    `moment_step`.

```{r}
# The date of landing and moment of step
date_landing <- mdy("July 20, 1969")
moment_step <- mdy_hms("July 20, 1969, 02:56:15", tz = "UTC")

# How many days since the first man on the moon?
difftime(today(), date_landing, units = "days")

# How many seconds since the first man on the moon?
difftime(now(), moment_step, units = "secs")
```

## **How many seconds are in a day?**

How many seconds are in a day? There are 24 hours in a day, 60 minutes
in an hour, and 60 seconds in a minute, so there should be `24*60*60` =
`86400` seconds, right?

Not always! In this exercise you'll see a counter example, can you
figure out what is going on?

**Instructions**

We've put code to define three times in your script - noon on March
11th, March 12th, and March 13th in 2017 in the US Pacific timezone.

-   Find the difference in time between `mar_13` and `mar_12` in
    seconds. *This should match your intuition*.

-   Now, find the difference in time between `mar_12` and `mar_11` in
    seconds. *Surprised?*

```{r}
# Three dates
mar_11 <- ymd_hms("2017-03-11 12:00:00", 
  tz = "America/Los_Angeles")
mar_12 <- ymd_hms("2017-03-12 12:00:00", 
  tz = "America/Los_Angeles")
mar_13 <- ymd_hms("2017-03-13 12:00:00", 
  tz = "America/Los_Angeles")

# Difference between mar_13 and mar_12 in seconds
difftime(mar_13, mar_12, units = "secs")

# Difference between mar_12 and mar_11 in seconds
difftime(mar_12, mar_11, units = "secs")
```

Why would a day only have 82800 seconds? At 2am on Mar 12th 2017,
Daylight Savings started in the Pacific timezone. That means a whole
hour of seconds gets skipped between noon on the 11th and noon on the
12th.

## Video 3.2: Time spans

Time spans are hard because they don't have a constant meaning. You saw
an example in the previous exercise. Even though we say two datetimes
are a day apart, that doesn't mean they are exactly 86400 seconds apart.
To do addition with datetimes and timespans you need to be specific
about what you mean by a time span. For example, to add one day to a
datetime, you need to define what you mean by "one day".

### Time spans in `lubridate`

| **period** | **Duration** |
|---------------------------------|---------------------------------------|
| Human concept of a time span | Stopwatch concept of a time span |
| datetime + **period** of one day = same time on the next date | datetime + **duration** of one day = datetime + 86400 seconds = 24 hours later |
| variable length | fixed number of seconds |

### Creating a time span

```{r}
days()
```

```{r}
days(x = 2)
```

```{r}
ddays(2)
```

### Arithmetic with time spans

```{r}
2 * days()
```

```{r}
days() + days()
```

```{r}
ymd("2011-01-01") + days()
```

### Functions to create time spans

| Time span | Duration     | Period      |
|-----------|--------------|-------------|
| Seconds   | `dseconds()` | `seconds()` |
| Minutes   | `dminutes()` | `minutes()` |
| Hours     | `dhours()`   | `hours()`   |
| Days      | `ddays()`    | `days()`    |
| Weeks     | `dweeks()`   | `weeks()`   |
| Months    | \-           | `months()`  |
| Years     | `dyears()`   | `years()`   |

# **Adding or subtracting a time span to a datetime**

A common use of time spans is to add or subtract them from a moment in
time. For, example to calculate the time one day in the future from
`mar_11` (from the previous exercises), you could do either of:

```         
mar_11 + days(1) mar_11 + ddays(1) 
```

Try them in the console, you get different results! But which one is the
right one? It depends on your intent. If you want to account for the
fact that time units, in this case days, have different lengths (i.e.
due to daylight savings), you want a period `days()`. If you want the
time 86400 seconds in the future you use a duration `ddays()`.

In this exercise you'll add and subtract timespans from dates and
datetimes.

## **Instructions**

**100 XP**

-   It's Monday Aug 27th 2018 at 2pm and you want to remind yourself
    this time next week to send an email. Add a period of one week to
    `mon_2pm`.

-   It's Tuesday Aug 28th 2018 at 9am and you are starting some code
    that usually takes about 81 hours to run. When will it finish? Add a
    duration of 81 hours to `tue_9am`.

-   What were you doing five years ago? Subtract a period of 5 years
    from `today()`.

-   Subtract a duration of 5 years from `today()`. *Will this give a
    different date?*

```{r}
# Add a period of one week to mon_2pm
mon_2pm <- dmy_hm("27 Aug 2018 14:00")
mon_2pm + weeks(1)

# Add a duration of 81 hours to tue_9am
tue_9am <- dmy_hm("28 Aug 2018 9:00")
tue_9am + dhours(81)

# Subtract a period of five years from today()
today() - years(5)

# Subtract a duration of five years from today()
today() - dyears(5)
```

## **Arithmetic with timespans**

You can add and subtract timespans to create different length timespans,
and even multiply them by numbers. For example, to create a duration of
three days and three hours you could do: `ddays(3) + dhours(3)`, or
`3*ddays(1) + 3*dhours(1)` or even `3*(ddays(1) + dhours(1))`.

There was an eclipse over North America on 2017-08-21 at 18:26:40. It's
possible to predict the next eclipse with similar geometry by
calculating the time and date one
[**Saros**](https://eclipse.gsfc.nasa.gov/SEsaros/SEsaros.html) in the
future. A Saros is a length of time that corresponds to 223 Synodic
months, a Synodic month being the period of the Moon's phases, a
duration of 29 days, 12 hours, 44 minutes and 3 seconds.

Do just that in this exercise!

**Instructions**

-   Create a duration corresponding to one Synodic Month: 29 days, 12
    hours, 44 minutes and 3 seconds.

-   Create a duration corresponding to one Saros by multiplying
    `synodic` by 223.

-   Add `saros` to `eclipse_2017` to predict the next eclipse.

```{r}
# Time of North American Eclipse 2017
eclipse_2017 <- ymd_hms("2017-08-21 18:26:40")

# Duration of 29 days, 12 hours, 44 mins and 3 secs
synodic <- ddays(29) + dhours(12) + dminutes(44) + dseconds(3)

# 223 synodic months
saros <- synodic * 223

# Add saros to eclipse_2017
eclipse_2017 + saros
```

## **Generating sequences of datetimes**

By combining addition and multiplication with sequences you can generate
sequences of datetimes. For example, you can generate a sequence of
periods from 1 day up to 10 days with,

```         
1:10 * days(1) 
```

Then by adding this sequence to a specific datetime, you can construct a
sequence of datetimes from 1 day up to 10 days into the future

```         
today() + 1:10 * days(1) 
```

You had a meeting this morning at 8am and you'd like to have that
meeting at the same time and day every two weeks for a year. Generate
the meeting times in this exercise.

**Instructions**

-   Create `today_8am()` by adding a period of 8 hours to `today()`

-   Create a sequence of periods from one period of two weeks, up to 26
    periods of two weeks.

-   Add `every_two_weeks` to `today_8am`.

```{r}
# Add a period of 8 hours to today
today_8am <- today() + hours(8)

# Sequence of two weeks from 1 to 26
every_two_weeks <- 1:26 * weeks(2)

# Create datetime for every two weeks for a year
today_8am + every_two_weeks
```

## **The tricky thing about months**

What should `ymd("2018-01-31") + months(1)` return? Should it be 30, 31
or 28 days in the future? Try it. In general `lubridate` returns the
same *day of the month* in the next month, but since the 31st of
February doesn't exist `lubridate` returns a missing value, `NA`.

There are alternative addition and subtraction operators: `%m+%` and
`%m-%` that have different behavior. Rather than returning an `NA` for a
non-existent date, they roll back to the last existing date.

You'll explore their behavior by trying to generate a sequence for the
last day in every month this year.

**Instructions**

We've put `jan_31`, the date for January 31st this year in your
workspace.

-   Start by creating a sequence of 1 to 12 periods of 1 month.

-   Add `month_seq` to `jan_31`. *Notice what happens to any month where
    the 31st doesn't exist*

-   Now add `month_seq` to `jan_31` using the `%m+%` operator.

-   Try subtracting `month_seq` from `jan_31` using the `%m-%` operator.

```{r}
jan_31 <- as.Date("2025-01-31")

# A sequence of 1 to 12 periods of 1 month
month_seq <- 1:12 * months(1)

# Add 1 to 12 months to jan_31
jan_31 + month_seq

# Replace + with %m+%
jan_31 %m+% month_seq

# Replace + with %m-%
jan_31 %m-% month_seq
```

## Video 3.3: Intervals

### Creating intervals

`datetime1` `%--%` `datetime2`, or

`interval(datetime1, datetime2)`

```{r}
dmy("5 January 1961") %--% dmy("30 January 1969")
```

```{r}
interval(dmy("5 January 1961"), dmy("30 January 1969"))
```

### Operating on an interval

```{r}
beatles <- dmy("5 January 1961") %--% dmy("30 January 1969")
int_start(beatles)
```

```{r}
int_end(beatles)
```

```{r}
int_length(beatles)
```

```{r}
as.period(beatles)
```

```{r}
as.duration(beatles)
```

### Comparing intervals

```{r}
hendrix_at_woodstock <- mdy("August 17 1969")
```

```{r}
hendrix_at_woodstock %within% beatles
```

```{r}
hendrix <- dmy("01 October 1966") %--% dmy("16 September 1970")
```

```{r}
int_overlaps(beatles, hendrix)
```

### Which kind of time span?

Use:

-   **Intervals** when you have a *start* and an *end*

-   **Periods** when you are interested in human units

-   **Durations** if you are interested in seconds elapsed

You can create an interval by using the operator `%--%` with two
datetimes. For example `ymd("2001-01-01") %--% ymd("2001-12-31")`
creates an interval for the year of 2001.

Once you have an interval you can find out certain properties like its
start, end and length with `int_start()`, `int_end()` and `int_length()`
respectively.

```{r}
# monarchs dataset not available

# # Print monarchs
# print(monarchs)
# 
# # Create an interval for reign
# monarchs <- monarchs %>%
#   mutate(reign = from %--% to) 
# 
# # Find the length of reign, and arrange
# monarchs %>%
#   mutate(length = int_length(reign)) %>% 
#   arrange(desc(length)) %>%
#   select(name, length, dominion)
```

## **Comparing intervals and datetimes**

A common task with intervals is to ask if a certain time is inside the
interval or whether it overlaps with another interval.

The operator `%within%` tests if the datetime (or interval) on the left
hand side is within the interval of the right hand side. For example, if
`y2001` is the interval covering the year 2001,

```         
y2001 <- ymd("2001-01-01") %--% ymd("2001-12-31") 
```

Then `ymd("2001-03-30") %within% y2001` will return `TRUE` and
`ymd("2002-03-30") %within% y2001` will return `FALSE`.

`int_overlaps()` performs a similar test, but will return true if two
intervals overlap at all.

Practice to find out which monarchs saw Halley's comet around 1066.

**Instructions**

We've put `halleys` a data set describing appearances of Halley's comet
in your workspace.

-   Print `halleys` to examine the date. `perihelion_date` is the date
    the Comet is closest to the Sun. `start_date` and `end_date` are the
    range of dates the comet is visible from Earth.

-   Create a new column, `visible`, that is an interval from
    `start_date` to `end_date`.

-   You'll work with one appearance, extract the 14th row of `halleys.`

-   Filter `monarchs` to those where `halleys_1066$perihelion_date` is
    within `reign`.

-   Filter `monarchs` to those where `halleys_1066$visible` overlaps
    `reign`.

```{r}
# halleys dataset not available
# Print halleys
# halleys
# 
# # New column for interval from start to end date
# halleys <- halleys %>% 
#   mutate(visible = start_date %--% end_date)
# 
# # The visitation of 1066
# halleys_1066 <- halleys[14, ] 
# 
# # Monarchs in power on perihelion date
# monarchs %>% 
#   filter(halleys_1066$perihelion_date %within% reign) %>%
#   select(name, from, to, dominion)
# 
# # Monarchs whose reign overlaps visible time
# monarchs %>% 
#   filter(int_overlaps(halleys_1066$visible, reign)) %>%
#   select(name, from, to, dominion)
```

## **Converting to durations and periods**

Intervals are the most specific way to represent a span of time since
they retain information about the exact start and end moments. They can
be converted to periods and durations exactly: it's possible to
calculate both the exact number of seconds elapsed between the start and
end date, as well as the perceived change in clock time.

To do so you use the `as.period()`, and `as.duration()` functions,
parsing in an interval as the only argument.

Try them out to get better representations of the length of the monarchs
reigns.

**Instructions**

-   Create new columns for `duration` and `period` that convert `reign`
    into the appropriate object.

-   Examine the `name`, `duration` and `period` columns.

```{r}
# # monarchs dataset not available
# # New columns for duration and period
# monarchs <- monarchs %>%
#   mutate(
#     duration = as.duration(reign),
#     period = as.period(reign)) 
#     
# # Examine results    
# monarchs %>%
#   select(name, duration, period)
```

# Chapter 4: Problems in Practice

## Video 4.1: Time zones

### IANA Timezones

It may seem weird to use a region and city to label a timezone rather
than just an offset, but remember *offsets might change through the year
due to daylight savings*, and when, and if, daylight savings occurred
might have changed through history. To convert one set of datetimes to
another timezone requires a complete record of this history, and since
that history often isn't country specific, or country borders have
changed through time, a city is the easiest way to label it. This
database of timezones is managed by **Internet Assigned Numbers
Authority**, or **IANA**, the same organization that is also responsible
for handing out blocks of IP addresses to Regional Internet Registries.
The database was orginally compiled by Arthur David Olson, hence the
name of the R function, `OlsonNames`.

```{r}
Sys.timezone()
```

```{r}
head(OlsonNames())
length(OlsonNames())
```

### Setting and extracting

```{r}
mar_11 <- ymd_hms("2017-03-11 12:00:00",
                  tz = "America/Los_Angeles")
```

```{r}
tz(mar_11)
```

### Manipulating timezones

`force_tz()` - change the timezone without changing the clock time

```{r}
mar_11
```

```{r}
force_tz(mar_11, tzone = "America/New_York")
```

`with_tz()` - view the same instant in a different timezone

```{r}
with_tz(mar_11, tzone = "America/New_York")
```

## **Setting the timezone**

If you import a datetime and it has the wrong timezone, you can set it
with `force_tz()`. Pass in the datetime as the first argument and the
appropriate timezone to the `tzone` argument. Remember the timezone
needs to be one from `OlsonNames()`.

I wanted to watch New Zealand in the Women's World Cup Soccer games in
2015, but the times listed on the [**FIFA
website**](https://www.fifa.com/tournaments/womens/womensworldcup) were
all in times local to the venues. In this exercise you'll help me set
the timezones, then in the next exercise you'll help me figure out what
time I needed to tune in to watch them.

**Instructions**

I've put the times as listed on the FIFA website for games 2 and 3 in
the group stage for New Zealand in your code.

-   Game 2 was played in Edmonton. Use `force_tz()` to set the timezone
    of game 2 to `"America/Edmonton"`.

-   Game 3 was played in Winnipeg. Use `force_tz()` to set the timezone
    of game 3 to `"America/Winnipeg"`.

-   Find out how long the team had to rest between the two games, by
    using `as.period()` on the interval between `game2_local` and
    `game3_local`.

```{r}
# Game2: CAN vs NZL in Edmonton
game2 <- mdy_hm("June 11 2015 19:00")

# Game3: CHN vs NZL in Winnipeg
game3 <- mdy_hm("June 15 2015 18:30")

# Set the timezone to "America/Edmonton"
game2_local <- force_tz(game2, tzone = "America/Edmonton")
game2_local

# Set the timezone to "America/Winnipeg"
game3_local <- force_tz(game3, tzone = "America/Winnipeg")
game3_local

# How long does the team have to rest?
as.period(game2_local %--% game3_local)
```

## **Viewing in a timezone**

To view a datetime in another timezone use `with_tz()`. The syntax of
`with_tz()` is the same as `force_tz()`, passing a datetime and set the
`tzone` argument to the desired timezone. Unlike `force_tz()`,
`with_tz()` isn't changing the underlying moment of time, just how it is
displayed.

For example, the difference between `now()` displayed in the
"America/Los_Angeles" timezone and "Pacific/Auckland" timezone is 0:

```         
now <- now() with_tz(now, "America/Los_Angeles") -    with_tz(now,  "Pacific/Auckland") 
```

Help me figure out when to tune into the games from the previous
exercise.

**Instructions**

-   Most fans will tune in from New Zealand. Use `with_tz()` to display
    `game2_local` in New Zealand time. New Zealand is in the
    `"Pacific/Auckland"` timezone.

-   I'll be in Corvallis, Oregon. Use `with_tz()` to display
    `game2_local` my time. Corvallis is in the `"America/Los_Angeles"`
    timezone.

-   Finally, use `with_tz()` to display `game3_local` in New Zealand
    time.

```{r}
# What time is game2_local in NZ?
with_tz(game2_local, tzone = "Pacific/Auckland")

# What time is game2_local in Corvallis, Oregon?
with_tz(game2_local, tzone = "America/Los_Angeles")

# What time is game3_local in NZ?
with_tz(game3_local, tzone = "Pacific/Auckland")
```

## **Timezones in the weather data**

Did you ever notice that in the hourly Auckland weather data there was
another datetime column, `date_utc`? Take a look:

```         
tibble::glimpse(akl_hourly) 
```

The `datetime` column you created represented local time in Auckland,
NZ. I suspect this additional column, `date_utc` represents the
observation time in UTC (the name seems a big clue). But does it really?

Use your new timezone skills to find out.

**Instructions**

**100 XP**

The data is available in the `akl_hourly` data frame.

-   What timezone are `datetime` and `date_utc` currently in? Examine
    the head of the `datetime` and `date_utc` columns to find out.

-   Fix `datetime` to have the timezone for `"Pacific/Auckland"`.

-   Reexamine the head of the `datetime` column to check the times have
    the same clocktime, but are now in the right timezone.

-   Now tabulate up the difference between the `datetime` and `date_utc`
    columns. *It should be zero if our hypothesis was correct*.

```{r}
# Examine datetime and date_utc columns
head(akl_hourly$datetime)
head(akl_hourly$date_utc)
  
# Force datetime to Pacific/Auckland
akl_hourly <- akl_hourly %>%
  mutate(
    datetime = force_tz(datetime, tzone = "Pacific/Auckland"))

# Reexamine datetime
head(akl_hourly$datetime)
  
# Are datetime and date_utc the same moments
table(akl_hourly$datetime - akl_hourly$date_utc)
  
```

## **Times without dates**

For this entire course, if you've ever had a time, it's always had an
accompanying date, i.e. a datetime. But sometimes you just have a time
without a date.

If you find yourself in this situation, the `hms` package provides an
`hms` class of object for holding times without dates, and the best
place to start would be with `as.hms()`.

In fact, you've already seen an object of the `hms` class, but I didn't
point it out to you. Take a look in this exercise.

**Instructions**

**100 XP**

-   Use `read_csv()` to read in `"akl_weather_hourly_2016.csv"`.
    *`readr` knows about the `hms` class, so if it comes across
    something that looks like a time it will use it.*

-   In this case the `time` column has been parsed as a time without a
    date. Take a look at the structure of the `time` column to verify it
    has the class `hms`.

-   `hms` objects print like times should. Take a look by examining the
    head of the `time` column.

-   You can use `hms` objects in plots too. Create a plot with `time` on
    the x-axis, `temperature` on the y-axis, with lines grouped by
    `date`.

```{r}
# Import auckland hourly data 
akl_hourly <- read_csv("akl_weather_hourly_2016.csv")

# Examine structure of time column
str(akl_hourly$time)

# Examine head of time column
head(akl_hourly$time)

# A plot using just time
ggplot(akl_hourly, aes(x = time, y = temperature)) +
  geom_line(aes(group = make_date(year, month, mday)), alpha = 0.2)
```

## Video 4.2: More on importing and exporting datetimes

### Fast parsing

`parse_date_time()` can be slow because it's designed to be forgiving
and flexible.

```{r}

library(fasttime)

fastPOSIXct("2003-02-27")
```

### `fast_strptime()`

```{r}
x <- "2001-02-27"
parse_date_time(x, order = "ymd")
```

```{r}
x <- "2001-02-27"
fast_strptime(x, format = "%Y-%m-%d")
```

```{r}
fast_strptime(x, format = "%y-%m-%d")
```

### Exporting datetimes

`{# {r} # library(tidyverse) #  # akl_hourly %>%  #   select(datetime) %>%  #   write_csv("tmp.csv")`

### Formatting datetimes

```{r echo=TRUE}

my_stamp <- stamp("Tuesday October 10 2017")

# Multiple formats matched: "%A October %Om %y%d"(1), "%A %B %d %y%H"(1), "%A %B %y %d%H"(1), "%A %B %d %Y"(1), "%A October %m %y%d"(1), "%A October %H %M%S"(1), "Tuesday %Om %d %y%H"(1), "Tuesday %Om %y %d%H"(1), "Tuesday %Om %d %Y"(1), "Tuesday October %Om %y%d"(1), "Tuesday October %Om %Y"(1), "Tuesday %B %d %y%H"(1), "Tuesday %B %y %d%H"(1), "Tuesday %B %d %Y"(1), "Tuesday October %m %y%d"(1), "Tuesday October %m %Y"(1), "Tuesday October %H %M%S"(1), "%A %Om %d %y%H"(0), "%A %Om %y %d%H"(0), "%A %Om %d %Y"(0), "%A October %Om %Y"(0), "%A October %m %Y"(0)
# Using: "%A %B %y %d%H"
```

```{r}
my_stamp(ymd("2003-02-27"))
# [1] "Thursday February 03 2700"
```

## **Fast parsing with fasttime**

The `fasttime` package provides a single function `fastPOSIXct()`,
designed to read in datetimes formatted according to ISO 8601. Because
it only reads in one format, and doesn't have to guess a format, it is
really fast!

You'll see how fast in this exercise by comparing how fast it reads in
the dates from the Auckland hourly weather data (over 17,000 dates) to
`lubridate`s `ymd_hms()`.

To compare run times you'll use the `microbenchmark()` function from the
package of the same name. You pass in as many arguments as you want each
being an expression to time.

**Instructions**

**100 XP**

We've loaded the datetimes from the Auckland hourly data as strings into
the vector `dates`.

-   Examine the structure of `dates` to verify it is a string and in the
    ISO 8601 format.

-   Parse `dates` with `fasttime` and pipe to `str()` to verify
    `fastPOSIXct` parses them correctly.

-   Now to compare timing, call `microbenchmark` where the first
    argument uses `ymd_hms()` to parse `dates` and the second uses
    `fastPOSIXct()`.

```{r}
# library(microbenchmark)
# library(fasttime)
# 
# dates <- akl_hourly$date_utc
# 
# # Examine structure of dates
# str(dates)
# 
# # Use fastPOSIXct() to parse dates
# fastPOSIXct(dates) %>% str()
# 
# # Compare speed of fastPOSIXct() to ymd_hms()
# microbenchmark(
#   ymd_hms = ymd_hms(dates),
#   fasttime = fastPOSIXct(dates),
#   times = 20)
```

## **Fast parsing with lubridate::fast_strptime**

`lubridate` provides its own fast datetime parser: `fast_strptime()`.
Instead of taking an `order` argument like `parse_date_time()` it takes
a `format` argument and the format must comply with the `strptime()`
style.

As you saw in the video that means any character that represents a
datetime component must be prefixed with a `%` and any non-whitespace
characters must be explicitly included.

Try parsing `dates` with `fast_strptime()` and then compare its speed to
the other methods you've seen.

**Instructions**

`dates` is in your workspace again.

-   Examine the head of `dates`. *What components are present? What
    separators are used?*

-   Parse `dates` with `fast_strptime()` by specifying the appropriate
    format string.

-   Compare the timing of `fast_strptime()` to `fasttime` and
    `ymd_hms()`.

```{r}
# # Head of dates
# head(dates)
# 
# # Parse dates with fast_strptime
# fast_strptime(dates, 
#     format = "%Y-%m-%dT%H:%M:%SZ") %>% str()
# 
# # Comparse speed to ymd_hms() and fasttime
# microbenchmark(
#   ymd_hms = ymd_hms(dates),
#   fasttime = fastPOSIXct(dates),
#   fast_strptime = fast_strptime(dates, 
#     format = "%Y-%m-%dT%H:%M:%SZ"),
#   times = 20)
```

## **Outputting pretty dates and times**

An easy way to output dates is to use the `stamp()` function in
`lubridate`. `stamp()` takes a string which should be an example of how
the date should be formatted, and returns a function that can be used to
format dates.

In this exercise you'll practice outputting `today()` in a nice way.

**Instructions**

-   Create a `stamp()` based on the string `"Saturday, Jan 1, 2000"`.

-   Print `date_stamp`. *Notice it is a function.*

-   Pass `today()` to `date_stamp` to format today's date.

-   Now output today's date in American style `MM/DD/YYYY`.

-   Finally, use stamp based on the `finished` string I've put in your
    workspace to format `today()`.

```{r}
# Create a stamp based on "Saturday, Jan 1, 2000"
date_stamp <- stamp("Saturday, Jan 1, 2000")

# Print date_stamp
print(date_stamp)

# Call date_stamp on today()
date_stamp(today())

# Create and call a stamp based on "12/31/1999"
stamp("12/31/1999")(today())

# Use string finished for stamp()
# stamp(finished)(today())

```
